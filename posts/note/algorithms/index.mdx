---
title: Algorithms
date: 2022-10-25
---

# Big 0 알고리즘 복잡도

## 알고리즘 복잡도

알고리즘을 평가하는 척도로 사용되는 복잡도(complexity)라는 개념이 있다.

알고리즘의 복잡도의 개념은 코드의 길이보다는 코드를 실행했을 때의 성능과 효율, 확장성(scalability)에 관계가 깊다.
알고리즘의 복잡도를 분석할 때는 시간 측면에서는 얼마나 실행 속도가 빠른지를 보기도 하고, 공간 측면에서는 얼마나 많은 메모리가 쓰이는지를 보기도 한다.
전자를 **시간 복잡도(time complexity)** 라고 하고, 후자를 **공간 복잡도(space complexity)** 라고 한다.

일반적으로 처리할 데이터의 양이 많아질수록 대부분의 경우 알고리즘의 성능은 떨어지기 마련이다. 여기서 중요한 부분은 입력 데이터 증가량 대비
얼마큼의 실행 시간과 메모리 소모량이 늘어나는 지이다. 우수한 알고리즘일수록 처리할 데이터의 양이 증가함에 따라 성능 저하가 적게 나타나는 경향을 보인다.

알고리즘의 성능을 비교할 때 일반적으로 입력 데이터의 크기가 작을 때는 어떤 알고리즘이 우수한지 티가 잘 안 나지만,
입력 데이터의 크기가 커지면 커질수록 시간 복잡도가 높은 알고리즘은 오래 걸리고 공간 복잡도가 높은 알고리즘은 메모리를 많이 쓰게 된다.

## Big 0

최악의 조건에서 주어진 알고리즘이 입력 데이터 크기 대비 실행 시간이나 메모리 사용량이 얼마나 증가하는지를 수식으로 표현한다.

Big 0를 사용해서 복잡도를 분석할 때는 거시적으로 접근하면서 수식을 단순화시킨다. 예를 들어, 어떤 알고리즘에 크기가 `n`인 데이터가 주어졌을 때,
실행 시간이 $3n^2 + 5n + 100$ 으로 계산된다면, Big 0 계산법으로 $O(n^2)$ 가 된다. 즉, Big O 표현식에서는 수학적으로 가장 영향력이 큰 항만 고려되며,
그 항 앞에 붙은 상수도 의미가 없어지게 된다.

## O(1): Constant

`O(1)` 복잡도는 입력 데이터의 크기와 상관없이 항상 동일한 성능을 보여주는 알고리즘이다. 입력 데이터가 아무리 커지더라도, 시간 복잡도가 `O(1)`인 알고리즘은 실행 시간이 느려지지 않고,
공간 복잡도가 `O(1)`인 알고리즘은 고정된 크기의 메모리만 사용한다.

가장 대표적인 예로 해시 테이블(Hash Table)이라는 자료 구조를 들 수 있다. 해시 테이블에는 데이터를 많이 저장하든 적게 저장하든 데이터를 찾는데 걸리는 시간은 항상 동일한 것으로 알려져있다.
즉, 일반적으로 해시 테이블의 검색 알고리즘은 `O(1)`의 시간 복잡도를 보인다. 그러나 실제 코딩 시험에서, 특히 시간 측면에서 `O(1)`의 복잡도의 답안을 낼 수 있는 문제를 접할 가능성은 높지 않다.

## O(n): Linear

코딩 시험에서 가장 흔하게 접할 수 있는 알고리즘의 복잡도이다. `O(n)` 복잡도의 알고리즘은 입력 데이터의 크기가 늘어나는만큼 실행 시간 또는 메모리 성능이 저하되는 특징을 보인다.

코딩 문제를 풀다보면 `for`나 `while` 반복문을 이용해서 주어진 데이터를 순회해야하는 경우가 많다. 이렇게 배열의 모든 원소나 링크드 리스트(linked list)의 모든 노드에 접근해서 무언가를 처리하는 코드를 작성하고 있다면
해당 알고리즘의 시간 복잡도는 최소 `O(n)` 일 것이다.

반복문을 하나만 쓰든 여러개를 쓰든 중첩만 하지 않는다면 시간 복잡도는 `O(n)`의 범주에서 벗어나지 않는다. Big O 계산 방법에 따르면 `O(n)`과 `O(2n)`, `O(100n)`은 유의미한 차이를 내지 않기 때문이다.

## O(log(n)): Logarithmic

`O(n)` 보다 입력 데이터의 크기의 영향을 적게 받는 `O(log(n))`도 코딩 시험에서 자주 쓰이는 대표적인 복잡도이다. `O(log(n))` 복잡도의 알고리즘은 입력 데이터의 크기가 커지더라도 실행 시간이나 메모리 사용량이 크게 늘어나지 않는다.
좀 더 수학적으로 얘기하면 전형적인 로그 함수의 그래프처럼 x축의 입력 데이터가 커지면 커질수록, y축의 시간/공간 소모량은 더욱 완만하게 증가한다.

가장 유명한 `O(log(n))` 알고리즘으로 **이진 검색(binary search)** 을 들 수 있다. 이진 검색에서는 검색 범위가 계속해서 절반으로 줄어들기 때문에 모든 원소에 확인해야하는 선형 탐색(linear-search) 대비 데이터의 크기의 증가에 따른 성능 저하가 적다.

이진 트리(binary tree)나 힙(heap)을 다루는 코딩 문제에서도 `O(log(n))` 알고리즘을 어렵지 않게 만날 수 있다. 해시

## O(n \* log(n)): Super linear

`O(n)`과 `O(log(n))` 를 묘하게 섞어 놓은듯한 `O(n * log(n))`도 코딩시험에서 흔하게 만날 수 있는 복잡도이다. `O(n * log(n))` 복잡도는 `O(n)` 복잡도보다 `O(log(n))` 만큼 더 많이 입력 데이터의 크기에 영향을 받는다.

입력 데이터를 대상으로 정렬을 필요로 하는 대부분의 알고리즘이 `O(n * log(n))` 의 복잡도를 보여준다. 왜냐하면 대부분의 프로그래밍 언어에서 제공하는 정렬 알고리즘의 복잡도가 `O(log(n))` 수준이기 때문이다.

## $O(n^2)$: Quadratic, $O(n^3)$: Cubic

지금까지 다룬 복잡도에 비해 성능이 많이 떨어지긴 하지만 $O(n^2)$ 또는 $O(n^3)$ 도 코딩 시험에서 심심치 않게 볼 수 있는 복잡도이다. $O(n^2)$ 복잡도는 입력 데이터의 크기가 늘어난 2배만큼, $O(n^3)$ 복잡도는 3배 만큼 실행 시간이 늘어나거나 메모리 소모량이 증가한다. 예를 들어, 시간 복잡도가 $O(n^2)$ 인 알고리즘은 입력 데이터의 크기가 5배로 늘어나면 실행 시간은 그의 제곱인 25배로 늘어난다.

만약 코딩 시험에서 반복문 안에서 또 다른 반복문을 사용하고 계시다면 $O(n^2)$ 복잡도의 알고리즘을 작성하고 있으실 확률이 높다. 마찬가지로 반복문을 3단계로 중첩해서 사용하고 있다면 $O(n^3)$ 복잡도의 알고리즘이 된다고 볼 수 있다.

## ..ETC

이 외에도 $O(n^k)$: Polynomial, O(n!): Factorial 등이 있는데 코딩 테스트에서 거의 쓰이지 않는다.

## 복잡도 서열

`O(1)` > `O(log(n))` > `O(n)` > `O(n * log(n))` > $O(n^2)$ > $O(n^3)$ > $O(n^k)$

## 시간과 공간의 균형

공간 복잡도를 조금 희생하면 시간 복잡도 측면에서 훨씬 나은 알고리즘을 얻을 수 있는 경우가 있다. 따라서 본인의 코드의 실행 속도가 너무 느리다면,
메모리를 좀 더 사용해서 실행 시간을 단축할 수 있는 방법이 없는지 생각해보면 좋다.
