---
title: 빅데이터를 지탱하는 기술
date: 2022-10-29
description: 빅데이터를 지탱하는 기술을 읽고 기록하였습니다.
thumbnailUrl: /book/tech-for-bigdata/tech-for-bigdata.jpeg
tags: ["빅데이터를 지탱하는 기술"]
---

---

# 1. 빅데이터의 기초 지식

## 1-1 [배경] 빅데이터의 정착

    ### 분산 시스템에 의한 데이터 처리의 고속화

- **Hadoop과 NoSQL의 대두**

  ![](/book/tech-for-bigdata/hadoop.PNG)

- **Hadoop?**

  `Hadoop`은 '다수의 컴퓨터에서 대량의 데이터를 처리하기' 위한 시스템이다. 예를 들어, 전 세계의 웹페이지를 모아서 검색 엔진을 만들려면 방대한 데이터를 저장해둘 스토리지와 데이터를 순차적으로 처리할 수 있는 구조가 필요하다.
  그러기 위해서는 수백 대, 수천 대 단위의 컴퓨터가 이용되어야 하며, 그것을 관리하는 것이 `Hadoop`이라는 프레임워크다.

- **Hive의 등장**

  초기 `Hadoop` 은 데이터 처리의 내용을 기술하기 위해 자바 언어로 프로그래밍을 해야 했다. 그렇기 때문에 누구나 간단히 사용하지 못했다.
  이를 해결하기 위해 SQL과 같은 쿼리 언어를 `Hadoop`에서 실행하기 위한 소프트웨어로 `Hive`를 개발했다.

- **NoSQL 데이터베이스**

  NoSQL은 전통적인 RDB의 제약을 제거하는 것을 목표로 한 데이터베이스의 총칭이다.

  1. 다수의 키와 값을 관련지어 저장하는 '키 밸류 스토어(key-value store)' -> Redis
  2. JSON과 같은 복잡한 데이터 구조를 저장하는 '도큐멘트 스토어' -> MongoDB
  3. 여러 키를 사용하여 높은 확장성을 제공하는 '와이드 칼럼 스토어' -> Cassandra

  등이 있다.

- Hadoop과 NoSQL 데이터베이스 조합

  **NoSQL 데이터베이스에 기록하고 Hadoop으로 분산 처리하기**라는 흐름이 2012년부터 퍼지기 시작했다.

### 분산 시스템의 비즈니스 이용 개척

- **데이터 웨어하우스**

  일부 기업에서는 이전부터 데이터 분석을 기반으로 하는 **엔터프라이즈 데이터 웨어하우스**(enterprise data warehouse/EDW, 또는 **데이터 웨어하우스**/DWH)를 도입했다.

  다수의 데이터 분석 도구가 Hadoop에 대한 대응을 표명하여 대량의 데이터를 보존 및 집계하기 위해 Hadoop과 Hive를 사용하게 되었다.
  그 결과 Hadoop의 도입을 기술적으로 지원하는 비즈니스가 성립하게 되었고 그때 사용하게 된 키워드가 바로 **빅데이터** 이다.

  ![](/book/tech-for-bigdata/data-warehouse.PNG)

### 직접 할 수 있는 데이터 분석 폭 확대

- **Amazon Redshift**

  2012년 말 **Amazon Redshift**(아마존 레드시프트)가 발표된 이후로 데이터 웨어하우스를 클라우드 상에서 작성하는 것이 쉬워졌다.

- **데이터 디스커버리(data discovery)**

  데이터 웨어하우스에 저장된 데이터를 시각화하려는 방법으로 **데이터 디스커버리**(data discovery)가 인기를 끌게 되었다.
  데이터 디스커버리란 '대화형으로 데이터를 시각화하여 가치 있는 정보를 찾으려고 하는 프로세스'를 가리키고 '셀프서비스용 **BI 도구**(business intelligence tool)' 로 불린다.

  **BI 도구**는 시각화 시스템이다.

## 1-2 빅데이터 시대의 데이터 분석 기반

### [재입문] 빅데이터의 기술

- **데이터 파이프라인**

  차례대로 전달해나가는 데이터로 구성된 시스템을 **데이터 파이프라인(data pipeline)** 이라고 한다.

- **데이터 수집**

  데이터 파이프라인은 데이터를 모으는 부분부터 시작한다.

  - **데이터 전송(data transfer)**

    1. 벌크(bulk)형

       이미 어딘가에 존재하는 데이터를 정리해 추출하는 방법으로, 데이터베이스와 파일 서버 등에서 정기적으로 데이터를 수집하는 데에 사용한다.

    2. 스트리밍(streaming)형

       차례차례로 생성되는 데이터를 끊임없이 계속해서 보내는 방법으로 모바일 애플리케이션과 임베디드 장비 등에서 널리 데이터를 수집하는 데 사용된다.

    ![](/book/tech-for-bigdata/work-flow.PNG)

- **스트림 처리와 배치 처리**

  1. 스트림 처리(streaming processing) : 스트리밍 형 방법으로 받은 데이터를 실시간으로 처리하는 것. 이는 장기적인 데이터 분석에는 적합하지 않음.
  2. 배치 처리(batch processing) : 장기적인 데이터 분석을 위한 분산 시스템.

- **분산 스토리지(distribute storage)**

  분산 스토리지란 여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템을 말함.

  1. 객체 스토리지(object storage) : 한 덩어리로 모인 데이터에 이름을 부여해서 파일로 저장함. ex) Amazon S3
  2. NoSQL 데이터베이스 : 애플리케이션에서 많은 데이터를 읽고 쓰려면 NoSQL 데이터베이스가 성능 면에서 우수함.

- **분산 데이터 처리(distribute data processing)**

  분산 스토리지에 저장된 데이터를 처리하는 데는 `분산 데이터 처리`의 프레임워크가 필요함.
  주 역할은 나중에 분석하기 쉽도록 데이터를 가공해서 그 결과를 외부 데이터베이스에 저장하는 것.

  - 빅데이터를 SQL로 집계하는 두 가지 방법

    1. 쿼리 엔진(query engine) : 분산 스토리지 상의 데이터를 SQL로 집계함. ex) Hive / 대화형 쿼리 엔진
    2. ETL(extract-transform-load) 프로세스 : 데이터를 `추출(extract)` 하고, 그것을 `가공(transform)`한 후, 데이터 웨어하우스에 `로드(load)` 함.

    ![](/book/tech-for-bigdata/ETL.PNG)

    ETL 프로세스는 ①과 같이 데이터베이스의 바깥에서 데이터를 가공하는 경우와 ②처럼 데이터를 읽어 들인 후에 가공하는 경우가 있다.

- **워크플로 관리(workflow management)**

  전체 데이터 파이프라인의 동작을 관리하기 위해 이 기술을 사용한다. 매일 정해진 시간에 배치 처리를 스케쥴대로 실행하고, 오류가 발생한 경우에는 관리자에게 통지하는 목적으로 사용된다.

- **데이터 웨어하우스와 데이터 마트**

  ![](/book/tech-for-bigdata/data-mart.PNG)

  1. 데이터 웨어하우스는 `대량의 데이터를 장기 보존하는` 것에 최적화되어 있다.
  2. 정리된 데이터를 한 번에 전송하는 것은 뛰어나지만, 소량의 데이터를 자주 쓰고 읽는 데는 적합하지 않다.
  3. 업무 시스템을 위한 RDB나 로그 등을 저장하는 파일 서버를 **데이터 소스(data source)** 라고 한다.
  4. 데이터 웨어 하우스는 업무에 있어서 중요한 데이터 처리에 사용되기 때문에 아무때나 사용하는 것은 시스템의 과부하를 초래한다.
  5. 따라서 데이터 웨어하우스에서 필요한 데이터만을 추출하여 **데이터 마트(data mart)** 를 구축한다.

- **데이터 레이크**

  1. 모든 데이터를 원래의 형태로 축적해두고 나중에 그것을 필요에 따라 가공하는 구조가 필요하다.
  2. 빅데이터의 세계에서는 여러 곳에서 데이터가 흘러들어 오는 '데이터를 축적하는 호수'에 비유해 데이터의 축적 장소를 **데이터 레이크(data lake)** 라고 한다.

  ![](/book/tech-for-bigdata/data-lake.PNG)

- **데이터 분석가와 데이터 엔지니어**

  ![](/book/tech-for-bigdata/dif.PNG)
